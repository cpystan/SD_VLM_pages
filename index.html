<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models">
  <meta name="keywords" content="MLLM, Spatial Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models</title>
  <style>
    .bold {
        font-weight: bold;
    }
    .highlight {
      background-color: #CCF2FF; /* 浅蓝色背景 */
      }
    table {
        width: 100%;
    }
</style>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models</h1>
          <div class="is-size-3 publication-authors">
            <span class="author-block">NeurIPS 2025</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Pingyi Chen</a><sup>1,2</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Yujing Lou</a><sup>3</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Shen Cao</a><sup>3</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Jinhui Guo</a><sup>3</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Lubin Fan</a><sup>3</sup>,&nbsp&nbsp&nbsp</span>
            <br>
            <span class="author-block">Yue Wu<sup>3</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Lin Yang<sup>2</sup>,&nbsp&nbsp&nbsp</span>
            <span class="author-block">Lizhuang Ma</a><sup>4</sup>&nbsp&nbsp&nbsp</span>
            <span class="author-block">Jieping Ye<sup>3</sup>,&nbsp&nbsp&nbsp</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Zhejiang University &nbsp&nbsp&nbsp</span>
            <!-- <span class="author-block"><sup>2</sup>Alibaba Cloud Computing &nbsp&nbsp&nbsp</span> -->
            <span class="author-block"><sup>2</sup>Westlake University &nbsp&nbsp&nbsp</span>
            <span class="author-block"><sup>3</sup>Alibaba Cloud &nbsp&nbsp&nbsp</span>
            <span class="author-block"><sup>4</sup>Shanghai Jiaotong University &nbsp&nbsp&nbsp</span>
          </div>

          <!-- <div class="is-size-6 publication-authors"> -->
            <!-- <span class="author-block"><sup>*</sup>This work was done when Jingyu Lin was an intern at Alibaba Cloud.</span> -->
          <!-- </div> -->

          <!-- <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>&dagger;</sup>Equal contributions.</span>
          </div> -->

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>&dagger;</sup>Corresponding authors.</span> 
          </div>


          <div class="column has-text-centered">
<!--            <div class="publication-links">-->
<!--               PDF Link.-->
<!--              <span class="link-block">-->
<!--                <a href=""-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fas fa-file-pdf"></i>-->
<!--                  </span>-->
<!--                  <span>Paper</span>-->
<!--                </a>-->
<!--              </span>-->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.03844"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Yeyuqqwx/HybridGS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Huggingface Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/Eto63277/HybridGS/tree/main"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">&#129303</span>
                  <span>Data</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
 <div class="container">
   <div class="columns is-centered">
     <div class="column">
         <img src="static/images/1.png" alt="Teaser image."/>
         <h2 class="subtitle has-text-justified" style="font-size: 14px;">
          <b>SD-VLM</b> Our work (a) proposes Massive Spatial Measuring and Understanding (MSMU) dataset with precise spatial annotations, and (b) introduces a plug-and-play depth positional encoding method strengthening VLMs’ spatial awareness.
         </h2>
     </div>
   </div>
 </div>
</section>

<br>
<br>

<section class="hero teaser">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating high-quality novel view renderings of 3D Gaussian Splatting (3DGS) in scenes featuring transient objects is challenging. We propose a novel hybrid representation, termed as HybridGS, using 2D Gaussians for transient objects per image and maintaining traditional 3D Gaussians for the whole static scenes. Note that, the 3DGS itself is better suited for modeling static scenes that assume multi-view consistency, but the transient objects appear occasionally and do not adhere to the assumption, thus we model them as planar objects from a single view, represented with 2D Gaussians. Our novel representation decomposes the scene from the perspective of fundamental viewpoint consistency, making it more reasonable. Additionally, we present a novel multi-view regulated supervision method for 3DGS that leverages information from co-visible regions, further enhancing the distinctions between the transients and statics. Then, we propose a straightforward yet effective multi-stage training strategy to ensure robust training and high-quality view synthesis across various settings. Experiments on benchmark datasets show our state-of-the-art performance of novel view synthesis in both indoor and outdoor scenes, even in the presence of distracting elements.
          </p>
        </div>
      </div>
    </div>
  </div>
    <!-- / Abstract. -->
  </div>
</section>

<br>
<br>


<section class="hero teaser">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <img src="./static/images/2.jpg" />
        <figcaption>Figure: Pipeline.</figcaption>
        <div class="content has-text-justified">
          <p>
            Given a casually captured image sequence, we decompose the whole scene into 2D Gaussians for transient objects and 3D Gaussians for static scenes. To warm up, we start by training a basic 3DGS to capture static elements. This is followed by iterative training of 2D and 3D Gaussians, where our transients and statics are combined using an \(\alpha\)-blending strategy with masks to produce the final renderings. The masks provide guidance for 3D Gaussians in the iterative training stage. During the joint-training, both 2D and 3D Gaussians are trained to further optimize the decomposition results.
        </p>
        <p>
          Essentially, given a set of input images \(\{I_k | k=1,2,..., N\}\) with the corresponding camera parameters, for each view \(I\), the goal of our method is to reasonably decouple the transients \(I_t\) and statics \(I_s\) as follows:
        </p>
        <p>
          \[
          I = M_t \odot I_t + (1 - M_t) \odot I_s,
          \]
        </p>
        <p>
          where the \(M_t \in [0, 1]\) represents the transient mask, and \(\odot\) is per pixel multiplication. When a pixel's value in \(M_t\) approaches 1, it indicates a higher probability that the location is transient; conversely, a lower value suggests a greater likelihood that area is static.
        </p>

        <p>To achieve the goal, we decompose the whole 3D scene with two components: 
          <br>(1) <b>Multi-view consistent 3D Gaussians</b> is used for rendering \(I_s\), which leverages multi-view information from images and models the static scene with a set of unified 3D Gaussians. The multi-view inputs regulate the 3D Gaussians to be consistent and robust across the different views.
          <br>(2) <b>Single-view independent 2D Gaussians</b> is responsible for modeling \(I_t\), which enables our approach to handle the fact that images are casually captured with varying transients. Concretely, we form a set of view-independent 2D Gaussians to model transients as planar objects from a single view.
        </p>
        <p>
          This novel combination allows for a more precise and reasonable representation of 3D scenes, enabling better performance on novel views.
        </p>
        </div>
      </div>
    </div>
  </div>
</section>


<br>
<br>


<section class="hero teaser">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <div class="table-container">
            <table style="width: 100%;">
              <!-- 设置表格宽度为100% -->
              <caption>Table: Comparison on NeRF On-the-go Dataset</caption>
              <thead>
                <tr>
                  <th rowspan="3">Method</th>
                  <th colspan="6">Low Occlusion</th>
                  <th colspan="6">Medium Occlusion</th>
                  <th colspan="6">High Occlusion</th>
                </tr>
                <tr>
                  <th colspan="3">Mountain</th>
                  <th colspan="3">Fountain</th>
                  <th colspan="3">Corner</th>
                  <th colspan="3">Patio</th>
                  <th colspan="3">Spot</th>
                  <th colspan="3">Patio-High</th>
                </tr>
                <tr>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                  <th>PSNR</th>
                  <th>SSIM</th>
                  <th>LPIPS</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                    <td>RobustNeRF</td>
                    <td>17.54</td>
                    <td>0.496</td>
                    <td>0.383</td>
                    <td>15.65</td>
                    <td>0.318</td>
                    <td>0.576</td>
                    <td>23.04</td>
                    <td>0.764</td>
                    <td>0.244</td>
                    <td>20.39</td>
                    <td>0.718</td>
                    <td>0.251</td>
                    <td>20.65</td>
                    <td>0.625</td>
                    <td>0.391</td>
                    <td>20.54</td>
                    <td>0.578</td>
                    <td>0.366</td>
                </tr>
                <tr>
                    <td>NeRF On-the-go</td>
                    <td>20.15</td>
                    <td>0.644</td>
                    <td>0.259</td>
                    <td>20.11</td>
                    <td>0.609</td>
                    <td>0.314</td>
                    <td>24.22</td>
                    <td>0.806</td>
                    <td>0.190</td>
                    <td>20.78</td>
                    <td>0.754</td>
                    <td>0.219</td>
                    <td>23.33</td>
                    <td>0.787</td>
                    <td>0.189</td>
                    <td>21.41</td>
                    <td>0.718</td>
                    <td>0.235</td>
                </tr>
                <tr>
                    <td>3DGS</td>
                    <td>19.40</td>
                    <td>0.638</td>
                    <td class="bold"><span class="highlight">0.213</span></td>
                    <td>19.96</td>
                    <td>0.659</td>
                    <td class="bold"><span class="highlight">0.185</span></td>
                    <td>20.90</td>
                    <td>0.713</td>
                    <td>0.241</td>
                    <td>17.48</td>
                    <td>0.704</td>
                    <td>0.199</td>
                    <td>20.77</td>
                    <td>0.693</td>
                    <td>0.316</td>
                    <td>17.29</td>
                    <td>0.604</td>
                    <td>0.363</td>
                </tr>
                <tr>
                    <td>SLS-mlp*</td>
                    <td>19.84</td>
                    <td>0.580</td>
                    <td>0.294</td>
                    <td>20.19</td>
                    <td>0.612</td>
                    <td>0.258</td>
                    <td>24.03</td>
                    <td>0.795</td>
                    <td>0.258</td>
                    <td>21.55</td>
                    <td class="bold"><span class="highlight">0.838</span></td>
                    <td class="bold"><span class="highlight">0.065</span></td>
                    <td>23.52</td>
                    <td>0.756</td>
                    <td class="bold"><span class="highlight">0.185</span></td>
                    <td>20.31</td>
                    <td>0.664</td>
                    <td>0.259</td>
                </tr>
                <tr>
                    <td>HybridGS (Ours)</td>
                    <td class="bold"><span class="highlight">21.73</span></td>
                    <td class="bold"><span class="highlight">0.693</span></td>
                    <td>0.284</td>
                    <td class="bold"><span class="highlight">21.11</span></td>
                    <td class="bold"><span class="highlight">0.674</span></td>
                    <td>0.252</td>
                    <td class="bold"><span class="highlight">25.03</span></td>
                    <td class="bold"><span class="highlight">0.847</span></td>
                    <td class="bold"><span class="highlight">0.151</span></td>
                    <td class="bold"><span class="highlight">21.98</span></td>
                    <td>0.812</td>
                    <td>0.169</td>
                    <td class="bold"><span class="highlight">24.33</span></td>
                    <td class="bold"><span class="highlight">0.794</span></td>
                    <td>0.196</td>
                    <td class="bold"><span class="highlight">21.77</span></td>
                    <td class="bold"><span class="highlight">0.741</span></td>
                    <td class="bold"><span class="highlight">0.211</span></td>
                </tr>
            </tbody>
            </table>
          </div>
        </div>

        <div class="content has-text-justified">
          <div class="table-container">
            <table style="width: 100%;">
              <caption>Table: Comparison on RobustNeRF Dataset</caption>
                <thead>
                    <tr>
                        <th rowspan="2">Method</th>
                        <th colspan="3">Statue</th>
                        <th colspan="3">Android</th>
                        <th colspan="3">Yoda</th>
                        <th colspan="3">Crab (1)</th>
                        <th colspan="3">Crab (2)</th>
                    </tr>
                    <tr>
                        <th>PSNR</th>
                        <th>SSIM</th>
                        <th>LPIPS</th>
                        <th>PSNR</th>
                        <th>SSIM</th>
                        <th>LPIPS</th>
                        <th>PSNR</th>
                        <th>SSIM</th>
                        <th>LPIPS</th>
                        <th>PSNR</th>
                        <th>SSIM</th>
                        <th>LPIPS</th>
                        <th>PSNR</th>
                        <th>SSIM</th>
                        <th>LPIPS</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>RobustNeRF</td>
                        <td>20.60</td>
                        <td>0.76</td>
                        <td>0.15</td>
                        <td>23.28</td>
                        <td>0.75</td>
                        <td>0.13</td>
                        <td>29.78</td>
                        <td>0.82</td>
                        <td>0.15</td>
                        <td>32.22</td>
                        <td>0.94</td>
                        <td>0.06</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>NeRF On-the-go</td>
                        <td>21.58</td>
                        <td>0.77</td>
                        <td>0.24</td>
                        <td>23.50</td>
                        <td>0.75</td>
                        <td>0.21</td>
                        <td>29.96</td>
                        <td>0.83</td>
                        <td>0.24</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>3DGS</td>
                        <td>21.02</td>
                        <td>0.81</td>
                        <td>0.16</td>
                        <td>23.11</td>
                        <td>0.81</td>
                        <td>0.13</td>
                        <td>26.33</td>
                        <td>0.91</td>
                        <td>0.14</td>
                        <td>31.80</td>
                        <td>0.96</td>
                        <td>0.08</td>
                        <td>29.74</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>SLS-mlp</td>
                        <td>22.54</td>
                        <td>0.84</td>
                        <td>0.13</td>
                        <td>25.05</td>
                        <td class="bold"><span class="highlight">0.85</span></td>
                        <td>0.09</td>
                        <td>33.66</td>
                        <td class="bold"><span class="highlight">0.96</span></td>
                        <td>0.10</td>
                        <td>35.85</td>
                        <td class="bold"><span class="highlight">0.97</span></td>
                        <td>0.08</td>
                        <td>34.43</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>HybridGS (Ours)</td>
                        <td class="bold"><span class="highlight">22.93</span></td>
                        <td class="bold"><span class="highlight">0.87</span></td>
                        <td class="bold"><span class="highlight">0.10</span></td>
                        <td class="bold"><span class="highlight">25.15</span></td>
                        <td class="bold"><span class="highlight">0.85</span></td>
                        <td class="bold"><span class="highlight">0.07</span></td>
                        <td class="bold"><span class="highlight">35.32</span></td>
                        <td class="bold"><span class="highlight">0.96</span></td>
                        <td class="bold"><span class="highlight">0.07</span></td>
                        <td class="bold"><span class="highlight">36.31</span></td>
                        <td class="bold"><span class="highlight">0.97</span></td>
                        <td class="bold"><span class="highlight">0.05</span></td>
                        <td class="bold"><span class="highlight">35.17</span></td>
                        <td class="bold"><span class="highlight">0.96</span></td>
                        <td class="bold"><span class="highlight">0.08</span></td>
                    </tr>
                </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<br>
<br>


<section class="hero teaser">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Visualization</h2>
        <img src="./static/images/4.jpg" />
        <figcaption>Figure: Visualization of novel view synthesis results on the testing set of NeRF On-the-go dataset.</figcaption>
        <br>
        <img src="./static/images/5.jpg" />
        <figcaption>Figure: Visualization of scene decomposition into transients and statics.</figcaption>
        <br>
        <video width="640" height="360" controls>
          <source src="./static/videos/Training_Process.mp4" type="video/mp4">
          <source src="video.webm" type="video/webm">
          <p>Your browser does not support HTML5 video. Here is a <a href="video.mp4">link to the video</a> instead.</p>
        </video>
        <figcaption>Figure: Qualitative results compared to 3DGS during the training steps.</figcaption>
        <div class="content has-text-justified">

        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Our method demonstrates superior results by effectively reducing artifacts and providing clearer boundaries. This results in a cleaner statics compared to other methods, showcasing enhanced visual quality and precision in novel views. 
          </p>
          <p>
            Also, our method achieves superior transient mask separation in both indoor and outdoor scenes. It effectively separates transients and statics, and the resulting renderings closely resemble the ground truth images, demonstrating its effectiveness.
          </p>
            Finally, as training iterations increase, 3DGS tends to gradually integrate transient elements into the static components, rendering the residuals being almost incapable of capturing transient contents. In contrast, our HybridGS effectively distinguishes transients from statics over time, leading to consistent improvements.
          <p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<br>
<br>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{lin2024hybridgs,
    author = {Jingyu Lin, Jiaqi Gu, Lubin Fan, Bojian Wu, Yujing Lou, Renjie Chen, Ligang Liu, Jieping Ye},
    title = {HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian Splatting},
    booktitle = {CVPR},
    year = {2025}
}</code></pre>
  </div>
</section>



</body>
</html>
